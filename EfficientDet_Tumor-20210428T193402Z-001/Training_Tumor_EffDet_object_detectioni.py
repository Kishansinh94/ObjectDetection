# -*- coding: utf-8 -*-
"""Object_detectionI_API_sucess_on_local.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15bkba0i95DwCVumGlyUEQ537rstRs8L1

https://www.youtube.com/watch?v=cvyDYdI2nEI&t=505s

Training working on machine done at 04-04-2021

Problem in detection may be due to short training because of low gpu power on local machine
"""

from google.colab import drive
drive.mount('/content/drive')

"""Install tensorflow object detection API on colab (Worked sucess on local)"""

!nvidia-smi

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/SSD_Tumor/models/research


!dir
#!git clone https://github.com/tensorflow/models.git

!protoc object_detection/protos/*.proto --python_out=.
#!cp /content/drive/MyDrive/Tensorflow-Object-Detection-API-Train-Model-master/models/research/object_detection/packages/tf2/setup.py .

!python -m pip install .

#setting up path

train_record_path = 'train.record'
test_record_path = 'test.record'
labelmap_path = 'training/labelmap.pbtxt'

#Setting up batch size
batch_size = 20
num_steps = 10000
num_eval_steps = 5

# Commented out IPython magic to ensure Python compatibility.
# %cd object_detection

"""Download pre-trained model and its config file and 2 times unzil folder and paste the final folder here models/research/object_detection/
Here I am using efficientdet_d0_coco17_tpu-32
"""

#Setting up checkpoint file path which is in downloaded pretrained folder
fine_tune_checkpoint = 'efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'

#Giving up config file path in my case i made new folder inside object_detetction and saved ssd_efficientdet_d0_512x512_coco17_tpu-8.config file there so accordingly set path here
base_config_path = 'training/ssd_efficientdet_d0_512x512_coco17_tpu-8.config'

# edit configuration file (from https://colab.research.google.com/drive/1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD)

import re

with open(base_config_path) as f:
    config = f.read()

with open('model_config.config', 'w') as f:
  
  # Set labelmap path
  config = re.sub('label_map_path: ".*?"', 
             'label_map_path: "{}"'.format(labelmap_path), config)
  
  # Set fine_tune_checkpoint path
  config = re.sub('fine_tune_checkpoint: ".*?"',
                  'fine_tune_checkpoint: "{}"'.format(fine_tune_checkpoint), config)
  
  # Set train tf-record file path
  config = re.sub('(input_path: ".*?)(PATH_TO_BE_CONFIGURED/train)(.*?")', 
                  'input_path: "{}"'.format(train_record_path), config)
  
  # Set test tf-record file path
  config = re.sub('(input_path: ".*?)(PATH_TO_BE_CONFIGURED/val)(.*?")', 
                  'input_path: "{}"'.format(test_record_path), config)
  
  # Set number of classes.
  config = re.sub('num_classes: [0-9]+',
                  'num_classes: {}'.format(4), config)
  
  # Set batch size
  config = re.sub('batch_size: [0-9]+',
                  'batch_size: {}'.format(batch_size), config)
  
  # Set training steps
  config = re.sub('num_steps: [0-9]+',
                  'num_steps: {}'.format(num_steps), config)
  
  # Set fine-tune checkpoint type to detection
  config = re.sub('fine_tune_checkpoint_type: "classification"', 
             'fine_tune_checkpoint_type: "{}"'.format('detection'), config)
  
  f.write(config)

# Commented out IPython magic to ensure Python compatibility.

# %cat model_config.config

# Commented out IPython magic to ensure Python compatibility.
#%load_ext tensorboard
# %tensorboard --logdir 'training/train'
# %reload_ext tensorboard

!dir
#Change directories to object detection folder in order to run files
#%cd /content/drive/MyDrive/Tensorflow-Object-Detection-API-Train-Model-master/models/research/object_detection

#Training dir

model_dir = 'training/'
pipeline_config_path = 'training/model_config.config'

!python model_main_tf2.py \
    --pipeline_config_path={pipeline_config_path} \
    --model_dir={model_dir} \
    --alsologtostderr \
    --num_train_steps={num_steps} \
    --sample_1_of_n_eval_examples=1 \
    --num_eval_steps={num_eval_steps}

#Creating graph
output_directory = 'inference_graph'

!python exporter_main_v2.py \
    --trained_checkpoint_dir {model_dir} \
    --output_directory {output_directory} \
    --pipeline_config_path {pipeline_config_path}

#Download models
from google.colab import files
files.download(f'{output_directory}/saved_model/saved_model.pb')

"""## **Test Model on dataset**"""

# Commented out IPython magic to ensure Python compatibility.
import io
import os
import scipy.misc
import numpy as np
import six
import time
import glob
from IPython.display import display

from six import BytesIO

import matplotlib
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont

import tensorflow as tf
from object_detection.utils import ops as utils_ops
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util

# %matplotlib inline

def load_image_into_numpy_array(path):
  """Load an image from file into a numpy array.

  Puts image into numpy array to feed into tensorflow graph.
  Note that by convention we put it into a numpy array with shape
  (height, width, channels), where channels=3 for RGB.

  Args:
    path: a file path (this can be local or on colossus)

  Returns:
    uint8 numpy array with shape (img_height, img_width, 3)
  """
  img_data = tf.io.gfile.GFile(path, 'rb').read()
  image = Image.open(BytesIO(img_data))
  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (im_height, im_width, 3)).astype(np.uint8)

# Commented out IPython magic to ensure Python compatibility.
#Guide to object detection
# %cd object_detection
!dir

category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)

tf.keras.backend.clear_session()
model = tf.saved_model.load('inference_graph/saved_model')

def run_inference_for_single_image(model, image):
  image = np.asarray(image)
  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
  input_tensor = tf.convert_to_tensor(image)
  # The model expects a batch of images, so add an axis with `tf.newaxis`.
  input_tensor = input_tensor[tf.newaxis,...]

  # Run inference
  model_fn = model.signatures['serving_default']
  output_dict = model_fn(input_tensor)

  # All outputs are batches tensors.
  # Convert to numpy arrays, and take index [0] to remove the batch dimension.
  # We're only interested in the first num_detections.
  num_detections = int(output_dict.pop('num_detections'))
  output_dict = {key:value[0, :num_detections].numpy() 
                 for key,value in output_dict.items()}
  output_dict['num_detections'] = num_detections

  # detection_classes should be ints.
  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)
   
  # Handle models with masks:
  if 'detection_masks' in output_dict:
    # Reframe the the bbox mask to the image size.
    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
              output_dict['detection_masks'], output_dict['detection_boxes'],
               image.shape[0], image.shape[1])      
    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.2,
                                       tf.uint8)
    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()
    
  return output_dict

for image_path in glob.glob('/content/drive/MyDrive/SSD_Tumor/test_images/*.JPG'):
  image_np = load_image_into_numpy_array(image_path)
  output_dict = run_inference_for_single_image(model, image_np)
  vis_util.visualize_boxes_and_labels_on_image_array(
      image_np,
      output_dict['detection_boxes'],
      output_dict['detection_classes'],
      output_dict['detection_scores'],
      category_index,
      instance_masks=output_dict.get('detection_masks_reframed', None),
      use_normalized_coordinates=True,
      line_thickness=8)
  display(Image.fromarray(image_np))